### 基础爬虫实现

1. 何为基础爬虫?

   基础爬虫，该爬虫的功能简单，仅仅只考虑了功能的实现，并未涉及到优化和稳健性的考虑，但是兼顾了基本上大大小小的爬虫都有的几个模块设计

2. 基础爬虫内部模块分析

   1. 模块分析:

      基础爬虫分为5个模块:爬虫调度器，URL管理器，HTML下载器，HTML解析器,数据存储器

      * 爬虫调度器 : 统筹其他4个模块的工作
      * URL管理器 : 维护两个队列，待爬取队列和已爬取队列，提供管理链接队列的接口
      * HTML下载器 : 用于从URL管理中去除链接并下载网页
      * HTML解析器 : 用于从已经下载的页面中解析出有效的新的URL和数据给数据存储器
      * 数据存储器 : 存储解析出来的数据

   2. 流程分析 :

      1. 是否存在可用的URL
      2. 获取一个新的URL
      3. 下载器获取新的URL开始现在页面
      4. 调度器将下载的页面交给解析器解析，并获取解析的数据
      5. 解析出的新的URL加入管理器队列，数据存储器存储有效的数据

   3. OOP

      * URL管理器:

        使用set容器管理我们的URL，目的是为了防止重复抓取造成死循环

        存储两个URL队列，并提供如下接口

        * has_new_url() - bool
        * add_new_url() / add_new_urls()
        * get_new_url() - URL(str)
        * new_url_size() - int
        * old_url_size() - int

      * HTML下载器:

        下载器需要使用到requests / urllib.request模块，并返回网页的文本

        只用提供一个下载接口即可

      * HTML解析器:

        HTML使用BeautifulSoup4进行解析，主要是提取链接和抽取百度百科词条的标题和信息

        笔记记录特殊的操作:

        1. Tag对象的get_text()方法返回文本

           返回所有的子节点的文档串(str的形式保存)，并且可以制定使用分隔符来拼接，默认没有分隔符号,separate参数可以指定(部分会注释文档串)

        2. urllib.parse.urljoin方法合并两个url路径构造新的url

      * 数据存储器:

        数据存储器提供一个接口用来存储HTML文档到文件中

      * 爬虫调度器

        初始化4个对象，使用接口run传入种子url开始工作调配

        ​


