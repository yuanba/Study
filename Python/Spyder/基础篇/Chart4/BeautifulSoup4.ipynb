{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是bs4\n",
    "1. beautifulsoup４(以下简称bs4)是一个可以从html , xml文档中抽取数据的python库，他可以支持很多的转换器实现文档的导航和查找检索功能，也可以实现修改功能\n",
    "2. beautiful soup可以使用很多的文档解析器，主要的解析器有html.parser / lxml / html5lib,在这里lxml备受推崇，因为lxml是以C语言为基础速度快，文档容错力强，基本上可以满足我们的所有的需求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bs4基本使用\n",
    "### 1.快速开始\n",
    "1. 库导入 / 例子导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml    #　导入解析器\n",
    "html_str = '''\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\"><!--Elsie--></a>,<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\"><!--Lacie--></a> and <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they livedat the bottom of a well.</p>\n",
    "<p class=\"story\">...'''    # lxml , bs4可以自动修正错误或者缺失的ｈｔｍｌ文档代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.创建BeautifulSoup对象  \n",
    "    * 字符串创建  \n",
    "    * 文件创建  \n",
    "     \n",
    "   我们需要知道，bs4会默认选择最合适的解析器来解释这段文本，但是也可以手动的定制解析器'lxml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    <!--Elsie-->\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    <!--Lacie-->\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they livedat the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# 字符串创建\n",
    "soup = BeautifulSoup(html_str , 'lxml' , from_encoding='utf8')    # 导入例子\n",
    "# 文件创建\n",
    "# soup = BeautifulSoup(open('html_str.html') , 'lxml' , from_encoding='utf8')\n",
    "\n",
    "#　字符串格式化\n",
    "print(soup.prettify())    # prettify函数生成格式化的字符串以便阅读打印\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.bs4主要对象\n",
    "   * Tag  \n",
    "        **BeautifulSoup对象比较特殊，我们可以理解为是一个document标记**  \n",
    "        tag通俗说就是我们的文档中的标记对象，包括标记本身和标记内的子对象(合称为一个Tag对象)  \n",
    "        Tag对象的两个重要属性\n",
    "        * name : 标记的名称,并且支持实时修改（影响当前的html_str）\n",
    "        * attrs : 标记的属性,支持实时修改\n",
    "            * 直接字典方式获取属性\n",
    "            * .attrs属性获取所有的属性的字典\n",
    "        * get_text()：  \n",
    "        返回所有的子节点的文档串(str的形式保存)，并且可以制定使用分隔符来拼接，默认没有分隔符号,separate参数可以指定(不抓取注释文档串)\n",
    "        方法不同于string属性，string属性返回的是报转过的字符串对象，这里的获取的是str文本对象  \n",
    "        **strip属性可以用来多余的空格和换行符号**\n",
    "   * NavigableString  \n",
    "       **Tag内部的文档属于NavigableString对象，可以使用str方法将NavigableString对象还原到str字符串的形式**  \n",
    "       .string方法可以获取Tag对象的NavigableString文档内容对象，string属性的特点是\n",
    "       * 标记里面没有标记，直接获取标记的文档内容\n",
    "       * 如果标记里面只有一个唯一的标记string会继续深入查找文档，并遵循第１点找到最里面的内容\n",
    "       * 但是如果标机里面有很多的子标记，那么string返回None\n",
    "   * BeautifulSoup  \n",
    "       bs对象表示的是文档整个内容，可以理解为是文档树的根，大部分的时候我们都把他当做是特殊的Tag对象，虽然没有name,attrs属性但是为了接口同意，bs对象还是有这些属性存在的\n",
    "   * Comment  \n",
    "       注释对象是特立独行的，上述的对象基本上涵盖了文档的所有的数据除了注释部分  \n",
    "       .string可以引用到注释的内容，但是他不是NavigableString对象而是Comment对象，我们在数据提取的时候对这一点需要明确注意\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [<title>The Dormouse's story</title>, <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>]\n",
      "2. [document] title\n",
      "4. {'class': ['title']} ['title'] ['title']\n",
      "6.1 The Dormouse's story <class 'bs4.element.NavigableString'> The Dormouse's story\n",
      "6.2 The Dormouse's story <class 'str'>\n",
      "6.3 None\n",
      "7. [document] {}\n",
      "8. Elsie <class 'bs4.element.Comment'>\n"
     ]
    }
   ],
   "source": [
    "# 抽取Tag对象\n",
    "print('1.' , [soup.title , soup.a])    # 但是这种方式抽取的对象只是文档中的第一出现的Tag对象\n",
    "print('2.' ,soup.name , soup.title.name)     #　Tag对象的name属性\n",
    "# soup.title.name = \"mytitle\"\n",
    "# print('3.' , soup.title , soup.mytitle)     # 支持实时修改\n",
    "# soup.mytitle.name = \"title\"    # 修正回来\n",
    "print('4.' , soup.p.attrs , soup.p['class'] , soup.p.get('class'))    #　获取Tag的属性\n",
    "# soup.p['class'] = 'myclass'\n",
    "# print('5.' , soup.p.attrs)\n",
    "# soup.p['myclass'] = 'class'\n",
    "\n",
    "# 从Tag中抽取NavigableString对象\n",
    "print('6.1' , soup.p.string , type(soup.p.string) , soup.p.string.string)\n",
    "print('6.2' , str(soup.p.string) , type(str(soup.p.string)))\n",
    "print('6.3' , soup.p.next_sibling.next_sibling.string)    # 第２个ｐ满足上面的分析的string的特点，返回None\n",
    "\n",
    "# bs对象的特殊和接口统一化\n",
    "print('7.' , soup.name , soup.attrs)\n",
    "\n",
    "# Comment对象的注意\n",
    "print('8.' , soup.a.string , type(soup.a.string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.文档树的遍历(**当前节点中包含下层节点**)  \n",
    "**bs4会将HTML文档转化成文档书来进行搜索，对于属性结构我们引入节点的概念**  　\n",
    "* 子节点  \n",
    "    每一个Tag对象我们可以理解成是一种自己点(但还有别的子节点,字符串也属于一种节点)  \n",
    "    \n",
    "    **获取子节点**  \n",
    "    \n",
    "    * contents 直接子节点列表\n",
    "    * children 直接子节点迭代器\n",
    "    * descendants 子孙节点迭代器  \n",
    "\n",
    "  **子节点数据提取**  \n",
    "  **我们会发现无论是Tag还是NavigableString对象都存在string属性，这意味着虽然是NavigableString字符串，但是做了接口统一都表示一种特殊的子节点，但是NavigableString的string属性获取的是自己本身**\n",
    "    * .string : \n",
    "        就像上面的描述一样，string属性针对我们的Tag对象/NavigableString对象\n",
    "    * .strings : 应用于Tag中存在**多个字符串子节点的情况**,抽取该Tag下所有的子节点的所有NavigableString对象（递归抽取，可以理解为这是一种**解析文档**的方法，抽取所有的节点下的正文）,返回迭代器\n",
    "    * .stripped_strings : 同strings，**但是会去除不必要的换行符号和空白符号单独构成的NavigableString对象**,返回迭代器\n",
    "* 父节点  \n",
    "    我们应该认识到，**每一个Tag或者NavigableString对象**都存在父节点（被包含在某一个Tag / soup中）  \n",
    "    **获取父节点**  \n",
    "    \n",
    "    * parent属性获取父节点\n",
    "    * parents属性获取所有父辈节点,返回迭代器\n",
    "* 兄弟节点  \n",
    "    兄弟节点和本节点处于同一个层级范围内，下面的属性获取的时候需要注意，NavigableString对象也属于节点，所有有识货我们想着要用这个方法去获得上一个Tag标签，往往是不尽如人意的\n",
    "    * next_sibling / next_siblings : 可以获取到下一个兄弟节点，不存在返回None，后者是一个迭代器\n",
    "    * previous_sibling / previous_siblings : 可以获取到上一个兄弟节点,不存在返回None，后者是一个迭代器\n",
    "* 前后节点  \n",
    "    **注释也算作前后结点**  \n",
    "    我们还是非常有必要来区分一下什么是兄弟节点什么是前后节点的  \n",
    "    首先兄弟节点表示的平行的关系，但是前后结点表示的递归的深入关系  \n",
    "    **NavigableString对象**代表着节点的终结，就像叶子节点一样,使用前后节点的搜索策略就相当于是在逐行的解析文档一样\n",
    "    * next_element : 后节点\n",
    "    * previous_element : 前节点\n",
    "    * next_elements : 后节点迭代器\n",
    "    * previous_elements : 前节点迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', <p class=\"title\"><b>The Dormouse's story</b></p>, '\\n', <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>,<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a> and <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they livedat the bottom of a well.</p>, '\\n', <p class=\"story\">...</p>, '\\n'] \n",
      " 7 \n",
      "\n",
      "0 \n",
      "\n",
      "1 <p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "2 \n",
      "\n",
      "3 <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>,<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a> and <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they livedat the bottom of a well.</p>\n",
      "4 \n",
      "\n",
      "5 <p class=\"story\">...</p>\n",
      "6 \n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "0 \n",
      " --------> <class 'bs4.element.NavigableString'> True\n",
      "1 <p class=\"title\"><b>The Dormouse's story</b></p> --------> <class 'bs4.element.Tag'> True\n",
      "2 <b>The Dormouse's story</b> --------> <class 'bs4.element.Tag'> True\n",
      "3 The Dormouse's story --------> <class 'bs4.element.NavigableString'> True\n",
      "4 \n",
      " --------> <class 'bs4.element.NavigableString'> True\n",
      "5 <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>,<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a> and <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they livedat the bottom of a well.</p> --------> <class 'bs4.element.Tag'> True\n",
      "6 Once upon a time there were three little sisters; and their names were\n",
      " --------> <class 'bs4.element.NavigableString'> True\n",
      "7 <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a> --------> <class 'bs4.element.Tag'> True\n",
      "8 Elsie --------> <class 'bs4.element.Comment'> True\n",
      "9 , --------> <class 'bs4.element.NavigableString'> True\n",
      "10 <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a> --------> <class 'bs4.element.Tag'> True\n",
      "11 Lacie --------> <class 'bs4.element.Comment'> True\n",
      "12  and  --------> <class 'bs4.element.NavigableString'> True\n",
      "13 <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a> --------> <class 'bs4.element.Tag'> True\n",
      "14 Tillie --------> <class 'bs4.element.NavigableString'> True\n",
      "15 ;\n",
      "and they livedat the bottom of a well. --------> <class 'bs4.element.NavigableString'> True\n",
      "16 \n",
      " --------> <class 'bs4.element.NavigableString'> True\n",
      "17 <p class=\"story\">...</p> --------> <class 'bs4.element.Tag'> True\n",
      "18 ... --------> <class 'bs4.element.NavigableString'> True\n",
      "19 \n",
      " --------> <class 'bs4.element.NavigableString'> True\n",
      "---------------------------------------------------------------------------------\n",
      "<class 'bs4.element.NavigableString'> \n",
      "\n",
      "<class 'bs4.element.NavigableString'> The Dormouse's story\n",
      "<class 'bs4.element.NavigableString'> \n",
      "\n",
      "<class 'bs4.element.NavigableString'> Once upon a time there were three little sisters; and their names were\n",
      "\n",
      "<class 'bs4.element.NavigableString'> ,\n",
      "<class 'bs4.element.NavigableString'>  and \n",
      "<class 'bs4.element.NavigableString'> Tillie\n",
      "<class 'bs4.element.NavigableString'> ;\n",
      "and they livedat the bottom of a well.\n",
      "<class 'bs4.element.NavigableString'> \n",
      "\n",
      "<class 'bs4.element.NavigableString'> ...\n",
      "<class 'bs4.element.NavigableString'> \n",
      "\n",
      "<class 'str'> The Dormouse's story\n",
      "<class 'str'> Once upon a time there were three little sisters; and their names were\n",
      "<class 'str'> ,\n",
      "<class 'str'> and\n",
      "<class 'str'> Tillie\n",
      "<class 'str'> ;\n",
      "and they livedat the bottom of a well.\n",
      "<class 'str'> ...\n"
     ]
    }
   ],
   "source": [
    "# contents属性生成所有的子节点的列表，children生成迭代器方便我们进行迭代\n",
    "print(soup.body.contents ,'\\n', len(soup.body.contents),'\\n')\n",
    "for i,j in enumerate(soup.body.children):\n",
    "    print(i , j)\n",
    "# 但是我们会发现，contents / children只包含直接子节点，并不会深入的递归的给出所有的子孙节点\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "#　如下我们会发现，对所有的自己点进行遍历的时候有些类似于树的深度有限搜索，并且字符串都属于一种节点\n",
    "for i , j in enumerate(soup.body.descendants):\n",
    "    print(i,j , '-------->',type(j) , hasattr(j , 'string'))\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "for i in soup.body.strings:\n",
    "    print(type(i) , i)\n",
    "# print(type(soup.body.stripped_strings))\n",
    "for i in soup.body.stripped_strings:\n",
    "    print(type(i) , i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p head\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>\n",
      "p\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "# parent属性获取直接父节点\n",
    "print(soup.a.parent.name , soup.title.parent.name)\n",
    "# parents属性获取所有父节点,可以看出来soup也是一种特殊的父节点\n",
    "print(soup.a)\n",
    "for parents in soup.a.parents:\n",
    "    print(parents.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>,<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a> and <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they livedat the bottom of a well.</p>\n",
      "0 \n",
      "\n",
      "1 <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>,<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a> and <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they livedat the bottom of a well.</p>\n",
      "2 \n",
      "\n",
      "3 <p class=\"story\">...</p>\n",
      "0 <class 'bs4.element.NavigableString'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 兄弟节点\n",
    "print(soup.p.next_sibling)    # \\n\n",
    "print(soup.p.previous_sibling)    # \\n\n",
    "print(soup.p.next_sibling.next_sibling)    # \\n的子节点就是下一个p,Tag对象\n",
    "\n",
    "for i,j in enumerate(soup.p.next_siblings):\n",
    "    print(i, j)\n",
    "for i,j in enumerate(soup.p.previous_siblings):\n",
    "    print(i,type(j) ,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 <head><title>The Dormouse's story</title></head>\n",
      "1.2 <title>The Dormouse's story</title> The Dormouse's story\n",
      "1.3 html\n",
      "2.1\n",
      "     0 Elsie\n",
      "     1 ,\n",
      "     2 <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a>\n",
      "     3 Lacie\n",
      "     4  and \n",
      "     5 <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "     6 Tillie\n",
      "     7 ;\n",
      "and they livedat the bottom of a well.\n",
      "     8 \n",
      "\n",
      "     9 <p class=\"story\">...</p>\n",
      "     10 ...\n",
      "2.2\n",
      "     1 p\n",
      "     4 b\n",
      "     5 p\n",
      "     7 body\n",
      "     10 title\n",
      "     11 head\n",
      "     12 html\n"
     ]
    }
   ],
   "source": [
    "# 前后结点\n",
    "\n",
    "import bs4\n",
    "\n",
    "print('1.1' , soup.head)\n",
    "print('1.2' , soup.head.next_element ,soup.head.next_element.next_element)\n",
    "print('1.3' , soup.head.previous_element.name)\n",
    "\n",
    "print('2.1')\n",
    "for i , j in enumerate(soup.a.next_elements):\n",
    "    print(' '* 4 ,  i , j)\n",
    "\n",
    "print('2.2')\n",
    "for i,j in enumerate(soup.a.previous_elements):\n",
    "    if isinstance( j , bs4.element.Tag) :     # 是标签节点的实例\n",
    "        print(' ' * 4 , i , j.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.搜索文档树(过滤节点)  \n",
    "**每一个节点都存在find_all方法可以使用**  \n",
    "    文档的搜索使用的主要的方法就是find_all / 类find方法，参数基本上都是一致的，这里主要记录find_all的使用方式  \n",
    "    find_all方法返回列表，列表中元素便是抽取出来的标记(Tag对象)  \n",
    "    **find_all方法的使用**  \n",
    "* 参数\n",
    "    * name \n",
    "        name参数在文档中查找所有名字(.name属性)符合的标记对象(**字符串节点忽略不考虑**，只剩下Tag对象)  \n",
    "        name 可以接收的对象有 : 字符串，正则表达式，列表，True,方法\n",
    "    * kwargs参数  \n",
    "        该参数在python中表示键参数，如果使用的是键参数并不是find_all函数的定义的键，那么搜索的时候会把这个键指定成Tag的属性来进行搜索  \n",
    "        可以使用的是字符串，正则表达式，列表，True   \n",
    "        有时候我们使用的键是有问题的\n",
    "        * class        : 因为class是python的保留关键字，我们只能使用class_避免\n",
    "        * data-foo ... :  \n",
    "        因为使用'-'符号在python中不成立，我们不能这么使用  \n",
    "        我们可以使用attrs字典参数指定(见下例子)(在Tag中我们见到过Tag的attrs字典参数，这里同意思)\n",
    "    * text参数  \n",
    "        text是用来搜索文档中的字符串内容的，使用字符串，正则表达式，列表，True  \n",
    "        **但是需要注意的是，抽取出来的文档有可能来自于注释，所以我们对数据的分析的时候需要小心一点**  \n",
    "    * limite参数  \n",
    "        find_all搜索的时候会搜索整个文档树，当文档很大的时候会导致处理速度很慢，当我们只需要少量的结果的时候，可以考虑使用Ｌｉｍｉｔｅ参数限制返回的结果的数量，当搜索到的结果到达限制搜索就会停止并返回结果\n",
    "    * recursive参数  \n",
    "        正如看到的那样，find_all方法是针对当前的节点搜索其内的所有的子节点（默认的recursive = True），如果我们限定只允许查找直接子节点可以将该参数制成False\n",
    "        \n",
    " \n",
    "\n",
    "其他的类似的函数的参数设置基本上都是类似的\n",
    "1. find : 同find_all但是只返回第一个查找结果，结果不是列表,可以理解为是find_all()[0]\n",
    "2. find_parent , find_next_siblings ....　查找其他的节点的内部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [<b>The Dormouse's story</b>] <class 'bs4.element.ResultSet'> <class 'bs4.element.Tag'>\n",
      "2.\n",
      "     html\n",
      "     title\n",
      "3. [<title>The Dormouse's story</title>, <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
      "4.\n",
      "     html\n",
      "     head\n",
      "     title\n",
      "     body\n",
      "     p\n",
      "     b\n",
      "     p\n",
      "     a\n",
      "     a\n",
      "     a\n",
      "     p\n",
      "5. [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "# find_all , name参数\n",
    "print('1' , soup.find_all(name = 'b') , type(soup.find_all(name = 'b')) , type(soup.find_all(name = 'b')[0]))   #　抽取b标记\n",
    "\n",
    "# 使用正则表达式搜索的时候，我们传入pattern的re对象，并自动进行匹配操作\n",
    "print('2.')\n",
    "import re\n",
    "for tag in soup.find_all(name = re.compile('t')):\n",
    "    print(' ' * 4 , tag.name)\n",
    "    \n",
    "#　如果传入的是列表，我们会将任何在列表中满足匹配条件的Tag对象插入进列表\n",
    "print('3.' , soup.find_all(name = ['a' , 'title']))\n",
    "\n",
    "#　如果传入的参数是True，会匹配所有的对象\n",
    "print('4.')\n",
    "for tag in soup.find_all(name = True):\n",
    "    print(' '* 4 , tag.name)\n",
    "    \n",
    "# 如果所有的上述方法还是不能满足需求，我们可以自定义方法作为过滤器,参数接受为Tag对象，返回True表示接收否则是不接受\n",
    "def haveclass(tag):\n",
    "    return tag.has_attr('class') and tag.has_attr('id')\n",
    "    # return hasattr(tag , 'class') and hasattr(tag, 'id') and hasattr(tag, 'href')    #　hasattr不可以过滤，只能用.has_attr过滤\n",
    "print('5.' , soup.find_all(name = haveclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
      "1.2\n",
      "     The Dormouse's story\t     None\t     Elsie\t     Lacie\t     Tillie\t     ...\t\n",
      "2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<div data-foo=\"value\">foo!</div>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find_all , kwargs参数\n",
    "print('1.1' , soup.find_all(href = re.compile('http://*')))    #　href不是find_all的参数名，当做某一个标签的属性来过滤\n",
    "print('1.2')    #　存在id的Tag对象,class比较特殊，因为class是python保留关键字，所以我们必须要使用class_避免重用\n",
    "for i in soup.find_all(class_ = True):\n",
    "    print(' '*4 , i.string , end = '\\t')\n",
    "print('\\n2.')\n",
    "data_soup = BeautifulSoup('<div data-foo=\"value\">foo!</div>' , 'lxml' , from_encoding='utf8')\n",
    "data_soup.find_all(attrs = {'data-foo' : 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ['Elsie']\n",
      "2. ['Elsie', 'Lacie', 'Tillie']\n",
      "3. ['Once upon a time there were three little sisters; and their names were\\n', ' and ', ';\\nand they livedat the bottom of a well.']\n"
     ]
    }
   ],
   "source": [
    "# find_all , text参数\n",
    "print('1.' , soup.find_all(text = 'Elsie'))    # 来自注释的ｃｏｍｍｅｎｔ对象\n",
    "print('2.' , soup.find_all(text = ['Tillie' , 'Elsie' , 'Lacie']))\n",
    "print('3.' , soup.find_all(text = re.compile(r'\\band\\b')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"><!--Elsie--></a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"><!--Lacie--></a>]\n"
     ]
    }
   ],
   "source": [
    "# find_all , limite参数\n",
    "print(soup.html.find_all(name = 'a' , limit=2))    #　符合条件的有３个，但是返回结果只有前两个,本例是针对html的find_all方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>The Dormouse's story</title>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# find_all , recursive递归参数\n",
    "print(soup.find_all(name = 'title'))\n",
    "print(soup.find_all(name = 'title' , recursive=False))    #　ｓｏｕｐ下直接子节点只有ｈｔｍｌ不存在ｔｉｔｌｅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **搜索文档树的CSS选择器方法** \n",
    "1. SS选择器的检索方法需要我们熟悉CSS选择器参考手册  http://www.w3school.com.cn/cssref/css_selectors.asp  \n",
    "2. 这样的语法非常的复杂，我们使用使用注意的思想直奔主题，采用FireBug对CSS搜索直接生成，下面的例子采用扒取的baidu的首页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "filename , headers = urllib.request.urlretrieve('http://www.baidu.com','baidu.html')    #　保存在当前目录下作为参考\n",
    "\n",
    "soup = BeautifulSoup(open('baidu.html') , 'lxml' , from_encoding='utf8')    # 文件生成bs4对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-22220d0d4bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 查看的网页和扒取的网页不一致的原因 : 不一致不是在反爬虫，是异步加载导致的，右键查看页面源码的时候可能没包含 JS 插进去的内容，比如 Chrome 查看源码会重新页面请求一次，你应该用审查元素来看。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 异步加载的内容需要通过模拟接口的请求来获取内容。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#lg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "# e.g.扒取百度一下按钮的文档节点\n",
    "# FireBug生成的CSS路径是 : #su\n",
    "# soup.select(\"#su\")\n",
    "# 查看的网页和扒取的网页不一致的原因 : 不一致不是在反爬虫，是异步加载导致的，右键查看页面源码的时候可能没包含 JS 插进去的内容，比如 Chrome 查看源码会重新页面请求一次，你应该用审查元素来看。\n",
    "# 异步加载的内容需要通过模拟接口的请求来获取内容。\n",
    "soup.select(\"#lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除文档树中的节点的方法\n",
    "decompose方法，对tag对象调用该方法即可在文档书中删除对应的节点对象"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
